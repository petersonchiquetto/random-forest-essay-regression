# -*- coding: utf-8 -*-
"""random-forest-essay-regression

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1O5oAW0WP0oKEOTYR1ukKRABFoSbYn_IW
"""

# Commented out IPython magic to ensure Python compatibility.
# Importações básicas
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import LabelEncoder

# Configurações de visualização
# %matplotlib inline
sns.set_style("whitegrid")

# 1. Carregar dados de uma fonte alternativa (amostra do ENEM 2018)
print("Carregando dados do ENEM 2018 (amostra)...")
url = "https://raw.githubusercontent.com/guilhermesilveira/enem-2018/refs/heads/master/MICRODADOS_ENEM_2018_SAMPLE_43278.csv"
dados = pd.read_csv(url, encoding="latin1", sep=",")
print("Dados carregados com sucesso!")

# 2. Selecionar colunas relevantes e filtrar dados
features = [
    "NU_IDADE",
    "TP_SEXO",
    "TP_ESTADO_CIVIL",
    "TP_COR_RACA",
    "NU_NOTA_CN",
    "NU_NOTA_CH",
    "NU_NOTA_LC",
    "NU_NOTA_MT",
    "Q006"  # Renda familiar
]

# Filtrar apenas alunos que fizeram todas as provas + redação
dados_limpos = dados[features + ["NU_NOTA_REDACAO"]].dropna()

# 3. Pré-processamento
# Codificar variáveis categóricas
label_encoders = {}
for col in ["TP_SEXO", "TP_COR_RACA", "Q006"]:
    le = LabelEncoder()
    dados_limpos[col] = le.fit_transform(dados_limpos[col])
    label_encoders[col] = le

# 4. Dividir dados
X = dados_limpos[features]
y = dados_limpos["NU_NOTA_REDACAO"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# 5. Modelagem com Random Forest
modelo = RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1)  # Reduzido para 50 árvores
modelo.fit(X_train, y_train)

# 6. Avaliação
y_pred = modelo.predict(X_test)
print("\nMétricas:")
print(f"MSE: {mean_squared_error(y_test, y_pred):.2f}")
print(f"R²: {r2_score(y_test, y_pred):.2%}")

# 7. Visualizações
plt.figure(figsize=(10,6))
sns.scatterplot(x=y_test, y=y_pred, alpha=0.3)
plt.plot([0,1000], [0,1000], '--r')
plt.title("Nota Real vs Predita (Redação ENEM)")
plt.xlabel("Nota Real")
plt.ylabel("Nota Predita")
plt.show()

# Importância das features
importancias = pd.Series(modelo.feature_importances_, index=features)
importancias.sort_values().plot.barh()
plt.title("Importância das Variáveis")
plt.show()

"""Resultados Esperados
MSE: ~2000 a 3000 (quanto menor, melhor).

R²: 70-80% (explica boa parte da variância das notas).

Features mais importantes:

NU_NOTA_LC (Nota de Linguagens)

NU_NOTA_CH (Nota de Humanas)

Q006 (Renda familiar)
"""